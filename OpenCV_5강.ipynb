{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V7fsp5lcgWqu"
   },
   "source": [
    "# Python OpenCV 입문 - 딥러닝 활용과 얼굴 검출\n",
    "## 얼굴 검출하는 방법\n",
    "* OpenCV에서 지원하는 얼굴 검출 기법\n",
    "    - Haar Cascade 방법\n",
    "        + 2001년 Viola & Jones에 의해 제안됨\n",
    "        + Haar-like 특징과 Adaboost 알고리즘, Cascade 구조를 사용하여 빠르고 정확하게  \n",
    "        얼굴 검출 수행\n",
    "    - DNN(Deep Neural Net) 방법\n",
    "        + OpenCV 3.3.1부터 DNN 모듈을 사용한 얼굴 검출 기본 예제 제공\n",
    "        + ResNet-10과 SSD를 기반으로 학습된 얼굴 검출 네트워크 사용\n",
    "        + 기존 Haar Cascade 방식 보다 빠르며 정확한 성능\n",
    "        + 정면, 측면, 가려짐이 있어도 검출 가능\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 기계학습의 개념\n",
    "인간과 컴퓨터의 차이는 뭘까? 인간은 하나를 알면 열을 알지만 과연 컴퓨터는..?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 기계학습의 정의\n",
    "미국의 컴퓨터 과학자 아서 사무엘은 1959년 다음과 같은 한 개념을 정의하였다.  \n",
    "기계가 일일이 코드로 명시하지 않은 동작을 데이터로부터 학습하여 실행할 수 있도록 하는 알고리즘을 개발하는 연구 분야\n",
    "\n",
    "<img src=\"https://quantdare.com/wp-content/uploads/2019/06/deep_learning-840x766.png\" width=\"650\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 기계학습의 종류\n",
    "* Supervised learning  \n",
    "    * 레이블로 분류된 데이터들을 학습시키는 방법\n",
    "        * 이메일 스팸 필터링\n",
    "        * 이미지 분류\n",
    "        * 성적 예측하기\n",
    "* Unsupervised learning\n",
    "    * 분류되지 않은, 즉 유사한 데이터들을 학습시키는 방법\n",
    "        * 유사한 뉴스들을 추천\n",
    "        * 동의어 검색\n",
    "  \n",
    "<img src=\"https://www.ceralytics.com/wp-content/uploads/2019/08/machine-learning.jpg\" width=\"650\">\n",
    "<img src=\"https://algorithmia.com/blog/wp-content/uploads/2018/04/Machine-Learning.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Supervised learning\n",
    "Supervised learning은 입력과 결과의 패턴을 학습시켜 학습하지 않은 패턴이 들어왔을 때 그것을 예측하는 방법으로 크게  \n",
    "Regression과 Classification 두 개의 범주로 나뉨\n",
    "* Regression\n",
    "    * 연속적인 값의 예측\n",
    "    * 성적에 따라 공부시간을 분석해 공부시간에 따른 성적 예측\n",
    "* Classification\n",
    "    * 레이블로 분류된 값의 예측\n",
    "    * 성적에 따라 Pass/Non-Pass로 나뉘는 Binary Classification\n",
    "    * 성적에 따라 A, B, C, D, F로 나뉘는 Multiclass Classification\n",
    "\n",
    "<img src=\"https://static.javatpoint.com/tutorial/machine-learning/images/regression-vs-classification-in-machine-learning.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Unsupervised learning\n",
    "Unsupervised learning은 컴퓨터가 스스로 자료를 모델링하는 학습 방법으로 Supervised learning과 달리 입력값에 따른 결과 주어지지 않음  \n",
    "Clustering, Dimensionality reduction 등이 사용\n",
    "* Clustering\n",
    "    * 플레이리스트에 따라 선호할 곡을 예측 및 추천  \n",
    "\n",
    "    <img src=\"https://3qeqpr26caki16dnhd19sv6by6v-wpengine.netdna-ssl.com/wp-content/uploads/2020/04/Scatter-Plot-of-Synthetic-Clustering-Dataset-With-Points-Colored-By-Known-Cluster.png\" width=\"500\" height=\"400\">\n",
    "* Dimensionality reduction\n",
    "    * 빅데이터의 시각화  \n",
    "\n",
    "    <img src=\"https://miro.medium.com/max/775/1*GoAgFuRFa8cTWSUB6d2mDA.png\" width=\"600\" height=\"600\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 텐서플로우(TensorFlow)\n",
    "<img src=\"https://www.gstatic.com/devrel-devsite/prod/veaa02889f0c07424beaa31d9bac1e874b6464e7ed7987fde4c94a59ace9487fa/tensorflow/images/lockup.svg\" width=\"300\" height=\"100\">  \n",
    "구글에서 제공하는 오픈소스 소프트웨어 라이브러리로 다양한 작업에 대한 데이터 흐름을 프로그래밍하기 위해 사용  \n",
    "GPU를 사용하여 이미지, 음성, 비디오 등의 데이터를 처리할 수 있다.  \n",
    "  \n",
    "활용 사례\n",
    "* 카카오\n",
    "    * 승차 요청 완료율 예측\n",
    "* 네이버 쇼핑\n",
    "    * 제품 카테고리 자동 분류"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 가상환경 설정하기\n",
    "1. python -m venv --system-site-packages .\\venv\n",
    "2. .\\venv\\Scripts\\activate\n",
    "3. pip install --upgrade pip\n",
    "4. python -m ipykernel install --user --name venv --display-name \"venv_kernel\"\n",
    "5. 화면 상단 Kernel - Change kernel - venv_kernel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 텐서플로우 설치하기\n",
    "1. pip install --upgrade tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.4.0\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5.Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1.1 Linear Regression\n",
    "회귀란 한 개 이상의 변수를 다룰 때 특정 변수와 다른 변수와의 관계를 분석하고 이를 토대로 모델을 정의해 값을 예측하는 방법  \n",
    "\n",
    "| 공부 시간(x)  | 시험 성적(y) |\n",
    "|:------------:|:-----------:|\n",
    "|     10       |     90   |\n",
    "|       9       |     80    |\n",
    "|      3        |     50    |\n",
    "|       2       |     30    |    \n",
    "<center> 7시간 공부한 학생의 점수를 예측할 수 있을까? </center>\n",
    "\n",
    "---\n",
    "\n",
    "<center>\n",
    "<img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/3/3a/Linear_regression.svg/1200px-Linear_regression.svg.png\" width=\"400\">\n",
    "그림 4: Linear Regression</center>  \n",
    "\n",
    "최적의 $W$와$b$를 찾는 과정\n",
    "\n",
    "* hypothesis\n",
    "\n",
    "  * $$h_{W,b}(x) = Wx + b$$\n",
    "\n",
    "  * hypothesis(가설)을 $H(x)$ 또는 $h(x)$라고 나타내고 $W$은 weigh  $b$은 bias를 의미\n",
    "\n",
    "\n",
    "* cost function \n",
    "  * 우리가 가지고 있는 모델이 실제 데이터와 얼마나 다른가를 나타내주는 함수  \n",
    "\n",
    "\\begin{align}\n",
    "J(W, b) &= \\frac{1}{2m}\\sum_{i=1}^{m}(\\hat{y}^{(i)} - y^{(i)})^2 \\\\\n",
    "&= \\frac{1}{2m}\\sum_{i=1}^{m}(h(x^{(i)}) - y^{(i)})^2 \\\\\n",
    "&= \\frac{1}{2m}\\sum_{i=1}^{m}(Wx^{(i)} + b - y^{(i)})^2\n",
    "\\end{align}\n",
    "\n",
    "  * 실제값과 예측값의 차이의 제곱을 평균\n",
    "  * 제곱을 하는 이유는 오차 값이 음수가 나오지 않도록 하고 오차 값이 작을 때 보다 클때 더 패널티가 커지도록 하기 위함.\n",
    "  * 1/2을 곱한 이유는 미분했을 때 값을 간단히 나타내기 위함.  \n",
    "  \n",
    "* 경사하강법\n",
    "**cost값을 최소로 만드는 W와 b를 찾아내는 것이 목표**\n",
    "\n",
    "<img src=\"https://github.com/idebtor/KMOOC-ML/blob/master/ipynb/images/gradientDescent.png?raw=true\" width=\"400\">\n",
    "<center>그림 5: 경사(기울기) 하강법</center>  \n",
    "\n",
    "\n",
    "\\begin{align}\n",
    "  w_{new} &= w_{old} - \\eta \\nabla{CostFunction} \\\\\n",
    "  w_j :&= w_j + \\Delta w_j \\\\\n",
    "        &= w_j - \\eta\\nabla{J(w_j)}   \\tag{3} \n",
    "\\end{align}\n",
    "\n",
    "  * 기울기가 양수이면 왼쪽으로 움직이고 기울기가 음수이면 다음에는 오른 쪽으로 움직이게 됨.\n",
    "\n",
    "\n",
    "* Linear Regression Algorithm 프로세스\n",
    "  * 훈련 데이터 입력\n",
    "  * 손실 함수 계산\n",
    "  * 손실함수 값이 최소가 될 때 까지 W와 b를 바꾸며 반복\n",
    "  * 손실 함수 값이 최소일 때 학습종료"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6.Multilayer Perceptron의 개념\n",
    "기존의 퍼셉트론은 데이터를 선형적으로 분류하는데 적합한 알고리즘이다.\n",
    "<img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/8/8a/Perceptron_example.svg/500px-Perceptron_example.svg.png\">  \n",
    "하지만 퍼셉트론은 아래와 같은 명백한 한계를 가지고 있는데, 이를 XOR 문제라고 한다.\n",
    "<img src=\"https://saedsayad.com/images/Perceptron_XOR.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.1 XOR 문제 해결\n",
    "해당 문제의 해결 방법은 이러하다.\n",
    "1. 두 개의 퍼셉트론을 통해 영역을 분류\n",
    "2. 같은 공간으로 분류된 데이터를 하나의 값으로 변환\n",
    "3. 남은 데이터를 새로운 퍼셉트론을 통해 재분류\n",
    "\n",
    "<img src=\"https://camo.githubusercontent.com/4d387bb0c167bfd43d8fb4bf8bf3646c5e68879b/687474703a2f2f637073303731352e776565626c792e636f6d2f75706c6f6164732f372f342f302f332f37343033353438352f383030393031345f6f7269672e706e67\">\n",
    "\n",
    "입력층과 출력층밖에 존재하지 않는 기존의 퍼셉트론의 형태에서 중간에 퍼셉트론끼리 연결된 은닉층이 형성되고 이를 다층 퍼셉트론(Multilayer Perceptron,  MLP)이라고 한다. MLP를 이루면서 비선형의 문제를 해결할 수 있게 된 것이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.2 Backpropagation\n",
    "<img src=\"https://miro.medium.com/max/2560/1*LB10KFg5J7yK1MLxTXcLdQ.jpeg\" width =\"600\">  \n",
    "\n",
    "입력과 결과를 알고있는 상태에서 신경망을 최적으로 학습시키는 알고리즘  \n",
    "특징\n",
    "* 가중치와 바이어스를 임의의 값으로 설정\n",
    "* 실제값과 결과값의 오차를 이용\n",
    "* 미분 가능한 Activation function 설정\n",
    "* Chain Rule 이용\n",
    "\n",
    "Chain Rule  \n",
    "* 두 함수 f와 g가 존재할 때의 chain rule  \n",
    "\n",
    "    <img src=\"https://mblogthumb-phinf.pstatic.net/MjAxODA0MDlfMTUw/MDAxNTIzMjY1MzMzODI1.G9Ou0NVTsNZO6VoXRJeAEzV0UjL3pott5OhB3JjEswMg.aMmCt2B8-pyvqi0yk9ZDV0aa4WtukiHi7UuyhcBj9_0g.PNG.complusblog/%EB%94%A5%EB%9F%AC%EB%8B%9D%28Deep_Learning%29_XOR_4.PNG?type=w800\" width=\"500\">  \n",
    "    <img src=\"https://mblogthumb-phinf.pstatic.net/MjAxODA0MDlfNTQg/MDAxNTIzMjY2MTE5NjI2.SMpgSUlF9n7UGpSnKHG9IcM8LsNn08EkEaQz1nrle3Ug.HoUICape3pmwXO-rv8mYSZJuye92u-OvlU7nLgQoR7wg.PNG.complusblog/%EB%94%A5%EB%9F%AC%EB%8B%9D%28Deep_Learning%29_XOR_6.png?type=w800\" width=\"400\">  \n",
    "    <img src=\"https://mblogthumb-phinf.pstatic.net/MjAxODA0MDlfMTE0/MDAxNTIzMjY2NTYyNTcy.ba3CMm4PMOyRffYgfCNTNotM7So676qZFqGLjYpv7_Yg.OjewIAk6OMAQUW_vbV4dz5h4TXqkSxES-ozvFvdUF4kg.PNG.complusblog/%EB%94%A5%EB%9F%AC%EB%8B%9D%28Deep_Learning%29_XOR_7.PNG?type=w800\" width=\"600\">  \n",
    "    <img src=\"https://mblogthumb-phinf.pstatic.net/MjAxODA0MDlfODcg/MDAxNTIzMjY2Nzg1MDc5.ybdMsHtTxUFvU5N0grLezD1CrmZy8uDEw0SYaRPQ_bAg.sjN7e3xNRpyvba9Eb7lQGHdAkcdd_iFLIr1kUoPetawg.PNG.complusblog/%EB%94%A5%EB%9F%AC%EB%8B%9D%28Deep_Learning%29_XOR_8.PNG?type=w800\" width=\"300\">  \n",
    "    α는 Learning rate, *cost*는 Cost function을 의미  \n",
    "    \n",
    "    위의 일련의 과정은 신경망을 학습시키기 위해 각 w, x, b가 결과값인 f에 미치는 영향도를 알기 위한 것이다. 그렇기 때문에 f라는 결과값을 입력값인 w, x, b로 미분하는 것이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.3 Deep learning\n",
    "DL은 MLP와 깊은 연관이 있다. MLP는 쉽게 말해, 1개 이상의 은닉층을 가지는 퍼셉트론을 지칭하는 것인데 여기서 은닉층이 2개 이상으로 늘어나면 이를 심층 신경망(Deep Neural Network, DNN)이라고 한다. DL은 이 심층 신경망을 통해 학습하는 방식을 말한다.\n",
    "<img src=\"https://user-images.githubusercontent.com/16768318/73028226-02399500-3e2d-11ea-85ea-0ea9998d8379.png\">\n",
    "\n",
    "종류\n",
    "* Convolutional Neural Network(CNN)\n",
    "    * 최소한의 전처리를 사용하도록 설계된 MLP의 한 종류\n",
    "        * 영상 분석\n",
    "* Recurrent Neural Network(RNN)\n",
    "    * 인공신경망을 구성하는 유닛 사이의 연결이 Directed cycle을 구성하는 신경망\n",
    "        * 번역기(ex.파파고)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.3.1 DL vs ML\n",
    "의미 없는 비교! 무엇인가 A.I가 되기 위해서까지는 ML이 없어서는 안 되고 ML은 DL이 없어서는 안 된다. 이것의 비교는 포유류와 강아지와 비교하는 것과 같다.\n",
    "\n",
    "굳이 따지자면\n",
    "* 처리가능한 데이터에 따른 성능\n",
    "* 하드웨어\n",
    "* 학습 시간\n",
    "* 데이터 셋의 입력"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7.CNN의 개념\n",
    "기존의 영상 인식은 학습한 내용만을 가지고 수행되었다. 다시 말해 자신이 학습한 것과 조금만 달라져도 인식을 할 수 없다는 이야기다.  \n",
    "<table>\n",
    "    <tr>\n",
    "        <td><img src=\"https://cdn.pixabay.com/photo/2018/03/31/06/31/dog-3277416_1280.jpg\" width=\"300\"></td>\n",
    "        <td><img src=\"https://cdn.pixabay.com/photo/2016/05/09/10/42/weimaraner-1381186_1280.jpg\" width=\"300\"></td>\n",
    "        <td><img src=\"https://cdn.pixabay.com/photo/2016/10/15/12/01/dog-1742295_1280.jpg\" width=\"265\"></td>\n",
    "        <td><img src=\"https://cdn.pixabay.com/photo/2016/02/11/17/00/dog-1194087_1280.jpg\" width=\"265\"></td>\n",
    "    </tr>\n",
    "</table>\n",
    "무릇 사람이라면 위의 사진들을 보고 생김새는 다르지만 개라는 것을 인지할 수 있다. \"이 객체는 ~한 특징을 가지니깐 개가 맞아\"가 아니라 그냥 경험적인 측면에서 어떻게 구체적으로 설명할 수는 없지만 개라는 것을 확신할 수 있게 된다.  \n",
    "\n",
    "하지만 컴퓨터는 저 사진 중 하나만을 학습했을 경우 나머지는 개라고 인식하지 못한다는 것이다. 그래서 등장한 것이 합성곱 신경망(CNN)이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.1 개념 심화\n",
    "컴퓨터가 인식하지 못하는 이유를 구체화하자면 다음과 같다.\n",
    "* 기존 영상 인식을 위해 사용되는 Fully Connected Layer는 영상의 전체 관계(topology)를 고려하지 못해, 데이터의 변형에 대응하지 못함\n",
    "* 영상의 특성상 특정 pixel은 주변 pixel과 관련이 있는데, input neuron에 입력신호를 넣기 위해 직렬화를 수행하면 pixel간 상관관계(locality)를 잃게 됨  \n",
    "* 정확도를 높이기 위해서는 변형된 영상의 학습데이터를 엄청나게 요구할 수 밖에 없는데, 데이터가 고해상도가 될 경우 input neuron이 급격하게 증가해 학습해야 할 parameter의 수가 급격하게 증가하는 문제 발생\n",
    "\n",
    "<img src=\"https://user-images.githubusercontent.com/15958325/58844125-bde86180-86b0-11e9-8d58-5d068c26233e.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.2 원리\n",
    "문제를 해결한 CNN의 원리는 다음과 같다.\n",
    "* 뇌 속 시각 피질의 신경 세포들은 물체의 방향과 장소가 바뀌어도 별문제 없이 인식할 수 있다는 점에서 착안\n",
    "* 객체 고유의 특징을 학습하여 물체의 위치와 방향에 관계없이 객체를 인식\n",
    "* 이미지의 픽셀 값으로부터 직접 시각 패턴을 학습\n",
    "* 각 레이어의 입출력 데이터 형상 유지\n",
    "* 이미지의 공간 정보를 유지하면서 이미지간 상관관계를 인식  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8.CNN 정의\n",
    "인공신경망의 한 종류로 적어도 하나의 계층에서 일반 행렬 곱셈 대신 합성곱을 수행하는 신경망\n",
    "  \n",
    "활용 사례\n",
    "* 영상 인식 및 처리\n",
    "* 메디컬 이미지 분석\n",
    "* 자연어 처리"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.1 구조\n",
    "<img src=\"https://miro.medium.com/max/3000/1*uAeANQIOQPqWZnnuH-VEyw.jpeg\">  \n",
    "CNN은 크게 Convolutional Layer, Pooling Layer, Fully Connected Layer로 구성되며 역할은 다음과 같다.  \n",
    "\n",
    "Feature Extraction\n",
    "* Convolutional Layer\n",
    "* Pooling Layer  \n",
    "\n",
    "Classification\n",
    "* Fully Connected Layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.1.1 Convolutional Layer\n",
    "Convolutional Layer는 여러 filter로 구성되어있고 filter를 통해 특징을 추출한다. 필터는 이미지 데이터를 일정 간격(Stride)으로 순회하며 연산을 수행한다. CNN은 이러한 필터들을 학습해 나간다.\n",
    "* Feature Map\n",
    "    * 실제 행렬 형태의 필터와 시각화된 필터\n",
    "    <table>\n",
    "        <tr>\n",
    "            <td><img src=\"https://adeshpande3.github.io/assets/Filter.png\"></td>\n",
    "            <td><img src=\"https://adeshpande3.github.io/assets/OriginalAndFilter.png\"></td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td></td>\n",
    "            <td></td>\n",
    "        </tr>\n",
    "    </table>  \n",
    "      \n",
    "    * 필터와 감지하고자 하는 특징이 비슷한 경우\n",
    "    <img src=\"https://adeshpande3.github.io/assets/FirstPixelMulitiplication.png\">  \n",
    "    * 필터와 감지하고자 하는 특징이 비슷하지 않은 경우\n",
    "    <img src=\"https://adeshpande3.github.io/assets/SecondMultiplication.png\">  \n",
    "    \n",
    "* Convolution filter\n",
    "    * 필터의 연산 과정  \n",
    "        <img src=\"https://user-images.githubusercontent.com/15958325/58780750-defb7480-8614-11e9-943c-4d44a9d1efc4.gif\">\n",
    "    * 특징 추출 과정  \n",
    "        <img src=\"https://i.stack.imgur.com/Hl2H6.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.1.2 Padding\n",
    "* 특징\n",
    "    * 합성곱 연산을 수행하기 전, 입력데이터 주변을 특정 값으로 채워 늘림\n",
    "    * 출력데이터의 공간적(Spatial) 크기를 조절\n",
    "    * 일반적으로 상하좌우 같은 크기와 값을 0으로 하는 padding 사용 (Zero-padding)  \n",
    "\n",
    "\n",
    "* 사용하는 이유\n",
    "    * 데이터의 공간적 크기는 Conv Layer를 지날 때마다 작아지면서 외각 정보들이 소실되는 문제 발생\n",
    "    * 크기가 작아지는 것을 막고 정보 소실 방지  \n",
    "    * Padding 처리 전, 후\n",
    "<img src=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=http%3A%2F%2Fcfile8.uf.tistory.com%2Fimage%2F990ACC345C666EBC1CBF64\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.1.3 Pooling Layer\n",
    "* 특징\n",
    "    * Conv Layer의 출력 데이터를 입력 받아서 크기를 줄이거나 특정 데이터를 강조하는 용도\n",
    "    * 출력 데이터에 일부분만을 취함(Spatial Sub-sampling)  \n",
    "    \n",
    "    \n",
    "* 사용하는 이유\n",
    "    * Overfitting 방지 및 계산량 감소\n",
    "    * Max Pooling 방식을 주로 사용\n",
    "    * 다양한 Pooling  \n",
    "    <img src=\"https://user-images.githubusercontent.com/15958325/58851117-60620e00-86cc-11e9-9b68-ce400aa93de0.png\" width=\"800\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.1.4 Fully Connected Layer\n",
    "* 특징\n",
    "    * 일반적인 Neural Network의 뉴런들 간의 연결 방법\n",
    "    * CNN에서는 Conv Layer에서 나온 이미지 특징을 가진 출력 데이터를 1차원으로 펴, 기존의 Neural Network에 연결하여 이미지를 효과적으로 학습\n",
    "    * Fully connected layer를 여러 층으로 구성하는 것이 가능하고 보통 마지막 FC layer에 Softmax를 적용하여 이미지 분류를 예측할 수 있게 model을 학습"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9. 전이학습"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9.1 전이학습의 개념\n",
    "    * 일반적으로 모든 층을 쌓아 모델을 설계하는 것은 비용이 많이 듦\n",
    "    * 많은 수의 데이터를 모아 가중치를 얻는 것도 비용이 많이 듦\n",
    "    * 아주 큰 데이터셋에 훈련된 가중치를 들고 와서 우리 데이터셋에 맞게 보정하여 사용하는 것을 전이학습이라고 함\n",
    "  <img src=\"https://t1.daumcdn.net/cfile/tistory/993EB3335A01540D03\" width=\"800\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9.2 대표적인 CNN 전이학습 모델\n",
    "* RESNET : 모델 구조가 간단하고 성능이 아주 좋은 모델\n",
    "\n",
    "  <img src=\"https://miro.medium.com/max/2628/1*S3TlG0XpQZSIpoDIUCQ0RQ.jpeg\" width=\"800\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 네트워크 입력 블롭(다차원행렬) 만들기\n",
    "\n",
    "```cv2.dnn.blobFromImage(image, scalefactor=None, size=None, mean=None, swapRB=None, crop=None, ddepth=None) -> retval```\n",
    "\n",
    "* 네트워크 불러오기\n",
    "\n",
    " ```cv2.dnn.readNet(model, config=None, framework=None) -> retval```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. DNN 실습\n",
    "## 10.1 사물 구분\n",
    "- 모델파일 : http://dl.caffe.berkeleyvision.org/bvlc_googlenet.caffemodel\n",
    "- 구성파일 : https://github.com/BVLC/caffe/tree/master/models/bvlc_googlenet 에서 deploy.prototxt 파일 다운로드\n",
    "- 클래스 이름 파일 : https://github.com/opencv/opencv/blob/4.1.0/samples/data/dnn/classification_classes_ILSVRC2012.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "\n",
    "filename = 'data/beagle.jpg'\n",
    "\n",
    "img = cv2.imread(filename)\n",
    "\n",
    "if img is None:\n",
    "    print('Image load failed!')\n",
    "    exit()\n",
    "\n",
    "# Load network\n",
    "\n",
    "net = cv2.dnn.readNet('data/bvlc_googlenet.caffemodel', 'data/deploy.prototxt')\n",
    "\n",
    "if net.empty():\n",
    "    print('Network load failed!')\n",
    "    exit()\n",
    "\n",
    "# Load class names\n",
    "\n",
    "classNames = None\n",
    "with open('data/classification_classes_ILSVRC2012.txt', 'rt') as f:\n",
    "    classNames = f.read().rstrip('\\n').split('\\n')\n",
    "\n",
    "# Inference\n",
    "\n",
    "inputBlob = cv2.dnn.blobFromImage(img, 1, (224, 224), (104, 117, 123))\n",
    "net.setInput(inputBlob)\n",
    "prob = net.forward()\n",
    "\n",
    "# Check results & Display\n",
    "\n",
    "out = prob.flatten()\n",
    "classId = np.argmax(out)\n",
    "confidence = out[classId]\n",
    "\n",
    "text = '%s (%4.2f%%)' % (classNames[classId], confidence * 100)\n",
    "cv2.putText(img, text, (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 0, 255), 1, cv2.LINE_AA)\n",
    "\n",
    "cv2.imshow('img', img)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10.2 얼굴 검출\n",
    "- 출력 : 4차원행렬\n",
    "- class, confidence, coordinate 정보 담고 있음\n",
    "- (1,1,N,7)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "\n",
    "model = 'res10_300x300_ssd_iter_140000_fp16.caffemodel'\n",
    "config = 'deploy2.prototxt'\n",
    "#model = 'opencv_face_detector_uint8.pb'\n",
    "#config = 'opencv_face_detector.pbtxt'\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "if not cap.isOpened():\n",
    "    print('Camera open failed!')\n",
    "    exit()\n",
    "\n",
    "net = cv2.dnn.readNet(model, config)\n",
    "\n",
    "if net.empty():\n",
    "    print('Net open failed!')\n",
    "    exit()\n",
    "\n",
    "while True:\n",
    "    _, frame = cap.read()\n",
    "    if frame is None:\n",
    "        break\n",
    "\n",
    "    blob = cv2.dnn.blobFromImage(frame, 1, (300, 300), (104, 177, 123))\n",
    "    net.setInput(blob)\n",
    "    detect = net.forward()\n",
    "\n",
    "    detect = detect[0, 0, :, :]\n",
    "    (h, w) = frame.shape[:2]\n",
    "\n",
    "    for i in range(detect.shape[0]):\n",
    "        confidence = detect[i, 2]\n",
    "        if confidence < 0.5:\n",
    "            break\n",
    "\n",
    "        x1 = int(detect[i, 3] * w)\n",
    "        y1 = int(detect[i, 4] * h)\n",
    "        x2 = int(detect[i, 5] * w)\n",
    "        y2 = int(detect[i, 6] * h)\n",
    "\n",
    "        cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0))\n",
    "\n",
    "        label = 'Face: %4.3f' % confidence\n",
    "        cv2.putText(frame, label, (x1, y1 - 1), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 0), 1, cv2.LINE_AA)\n",
    "\n",
    "    cv2.imshow('frame', frame)\n",
    "\n",
    "    if cv2.waitKey(1) == 27:\n",
    "        break\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10.3 성별 나이 검출\n",
    "- git 설치"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WinError 2] 지정된 파일을 찾을 수 없습니다: 'age_and_gender_detection'\n",
      "C:\\Users\\Admin\\Desktop\\OpenCV\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'git'은(는) 내부 또는 외부 명령, 실행할 수 있는 프로그램, 또는\n",
      "배치 파일이 아닙니다.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/misbah4064/age_and_gender_detection.git\n",
    "%cd age_and_gender_detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10.4 체크"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Attendance.csv', 'elon musk.jpg', 'jaeyoung lee.jpg', 'jeff bezos.jpg', 'steve jobs.jpg']\n",
      "['Attendance', 'elon musk', 'jaeyoung lee', 'jeff bezos', 'steve jobs']\n"
     ]
    },
    {
     "ename": "error",
     "evalue": "OpenCV(4.5.1) C:\\Users\\appveyor\\AppData\\Local\\Temp\\1\\pip-req-build-kh7iq4w7\\opencv\\modules\\imgproc\\src\\color.cpp:182: error: (-215:Assertion failed) !_src.empty() in function 'cv::cvtColor'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-fd425657a4fa>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 41\u001b[1;33m \u001b[0mencodeListKnown\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfindEncodings\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     42\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Encoding Complete'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-2-fd425657a4fa>\u001b[0m in \u001b[0;36mfindEncodings\u001b[1;34m(images)\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[0mencodeList\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mimg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mimages\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m         \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCOLOR_BGR2RGB\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m         \u001b[0mencode\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mface_recognition\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mface_encodings\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m         \u001b[0mencodeList\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mencode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.5.1) C:\\Users\\appveyor\\AppData\\Local\\Temp\\1\\pip-req-build-kh7iq4w7\\opencv\\modules\\imgproc\\src\\color.cpp:182: error: (-215:Assertion failed) !_src.empty() in function 'cv::cvtColor'\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import face_recognition\n",
    "import os\n",
    "from datetime import datetime\n",
    "path = 'attendance'\n",
    "images = []\n",
    "classNames = []\n",
    "myList = os.listdir(path)\n",
    "print(myList)\n",
    "for cl in myList:\n",
    "    curImg = cv2.imread(f'{path}/{cl}')\n",
    "    images.append(curImg)\n",
    "    classNames.append(os.path.splitext(cl)[0])\n",
    "print(classNames)\n",
    "\n",
    "def findEncodings(images):\n",
    "    encodeList = []\n",
    "    for img in images:\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        encode = face_recognition.face_encodings(img)[0]\n",
    "        encodeList.append(encode)\n",
    "    return encodeList\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "def markAttendance(name):\n",
    "    with open('Attendance.csv','r+') as f:\n",
    "        myDataList = f.readlines()\n",
    "        nameList = []\n",
    "        #print(myDataList)\n",
    "        for line in myDataList:\n",
    "            entry = line.split(',')\n",
    "            nameList.append(entry[0])\n",
    "        if name not in nameList:\n",
    "            now = datetime.now()\n",
    "            dtString = now.strftime('%H:%M:%S')\n",
    "            f.writelines(f'\\n{name},{dtString}')\n",
    "\n",
    "\n",
    "\n",
    "encodeListKnown = findEncodings(images)\n",
    "print('Encoding Complete')\n",
    "\n",
    "while True:\n",
    "    success, img = cap.read()\n",
    "    imgS = cv2.resize(img, (0,0), None, 0.25,0.25)\n",
    "    imgS = cv2.cvtColor(imgS, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    facesCurFrame = face_recognition.face_locations(imgS)\n",
    "    encodeCurFrame = face_recognition.face_encodings(imgS, facesCurFrame)\n",
    "\n",
    "    for encodeFace, faceLoc in zip(encodeCurFrame, facesCurFrame):\n",
    "        matches = face_recognition.compare_faces(encodeListKnown, encodeFace)\n",
    "        faceDis = face_recognition.face_distance(encodeListKnown, encodeFace)\n",
    "        #print(faceDis)\n",
    "        matchIndex = np.argmin(faceDis)\n",
    "\n",
    "        if matches[matchIndex]:\n",
    "            name = classNames[matchIndex].upper()\n",
    "            #print(name)\n",
    "            y1,x2,y2,x1 = faceLoc\n",
    "            y1, x2, y2, x1 = y1*4,x2*4,y2*4,x1*4\n",
    "            cv2.rectangle(img, (x1,y1),(x2,y2),(0,255,0),2)\n",
    "            cv2.rectangle(img, (x1,y2-35),(x2,y2),(0,255,0),cv2.FILLED)\n",
    "            cv2.putText(img, name, (x1+6, y2-6), cv2.FONT_HERSHEY_COMPLEX,1,(255,255,255),2)\n",
    "            markAttendance(name)\n",
    "\n",
    "\n",
    "    cv2.imshow('Webcam',img)\n",
    "    cv2.waitKey(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "OpenCV 4강",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "FaceRecognition",
   "language": "python",
   "name": "facerecognition"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
